{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osnabrück University - A&C: Computational Cognition (Summer Term 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Sheet 04: Analysis of behavioural data (part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This week's sheet should be solved and handed in at 14:00 at **Tuesday, May 14, 2019**. If you need help (and Google and other resources were not enough), feel free to contact your tutors. Please push your results to your Github group folder.\n",
    "\n",
    "In this exercise sheet we will have a closer look on the data of Seahaven using analysing techniques like ANOVA, linear regression models and t-tests. For the correct results we will provide you with the finalized data that you only have to read in. Note that especially the data for assignment 2 and 3 underwent some further preprocesing than what we did in the previous exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 0: Peer review for sheet 03 [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open an issue in the repository of the groups you have to check. The title of the issue should be your group name (e.g. \"Group1). Comment on what was good and what was bad, the aesthetics and ease of reading the plots, what you would have done differently and how many points you would give them for their solutions.\n",
    "\n",
    "| * |Group 1|Group 2|Group 3|Group 4|Group 5|Group 6|Group 7|Group 8|Group 9|Group 10|Group 11|\n",
    "| ------- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ----- | ------ | ------ |\n",
    "| check solutions of group: | 6, 2 | 10, 7  | 1, 6  | 8, 9 | 7, 1 | 9, 8 | 3, 10  | 5, 11  | 4, 3  | 11, 5 | 2, 4  |\n",
    "\n",
    "Please also evaluate nice coding style with up to two points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ptitprince'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-43863b02f93d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mptitprince\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ptitprince'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ptitprince as pt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from PIL import Image\n",
    "from scipy import stats\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.api import anova_lm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1: Linear Regression Model Based on Performance and Reaction Time [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the linear regression in the prior exercise sheet (assignment 2.a) does not suggest a relationship between RT and performance (accuracy) for the relative task, we still want to check how much of the performance is explained by the RT. To do so we fit a linear regression model by using the ```ols``` method in the ```statsmodels``` library for both of the time conditions (3sec and Infinite).\n",
    "\n",
    "- Read ```AllData.csv``` into the dataframe ```AllData``` and take only the data of the relative task. \n",
    "- Split the data of the relative task: Create ```SecData``` with the data of the 3sec-condition and ```InfData``` with the data of the Infinite-condition.\n",
    "- For each dataset (SecData, InfData) use the ```statsmodels```’ ```ols``` function to initialise a simple linear regression model. <br> The ```ols``` function takes the following: **ols(\"y ~ X\", df)**, where X is the predictor variable (\"ReactionTime\"), y is the output variable (\"Performance\") and df is the dataframe of the used data.\n",
    "- Have a look on the R-squared values and interpret them.\n",
    "\n",
    "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html) and the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) to get a feeling how to use the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read AllData.csv into the dataframe AllData and take only the data of the relative task.\n",
    "data = pd.read_csv('./Data/AllData.csv')\n",
    "\n",
    "#Split the data of the relative task\n",
    "data = data[data['Task']=='Relative']\n",
    "\n",
    "#Create SecData with the data of the 3sec-condition and InfData with the data of the Infinite-condition.\n",
    "SecData = data[data['Time']=='3sec']\n",
    "InfData = data[data['Time']=='Infinite']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ba5172e081de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#initialise a simple linear regression model to data of 3sec-condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSecOls\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Performance~ReactionTime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSecData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mSecOls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ols' is not defined"
     ]
    }
   ],
   "source": [
    "#initialise a simple linear regression model to data of 3sec-condition\n",
    "SecOls= ols('Performance~ReactionTime',data = SecData).fit()\n",
    "SecOls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise a simple linear regression model to data of infinite-condition\n",
    "InfOls= ols('Performance~ReactionTime',data = InfData).fit()\n",
    "InfOls.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpretation r-squared values\n",
    "print(\"R-squared is a goodness-of-fit measure for linear regression models - it gives a value of how much of the variance can be 'explained' by a factor. With time constraints this is the case for 4.2%, and 11,8 for no-time-constraints. Both are relatively low values but r-values always need to be seen in context with the demand of the circumstances.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Testing Task Performance via ANOVA [5 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment we will have a look on the whole data without caring about the different measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Task Performance [2 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refering to our plots of the prior exercise sheet (assignment 2.b), it is a good idea to have a closer look on the task performance (accuracy) to check if there are some **significant effects, i.e. p < 0.05**. To do so we will first of all visualize the data with a raincloud-plot using ```ptitprince.RainCloud``` as a density estimate and then calculate the ANOVAs. Make sure to run ```pip install ptitprince``` in your activated acc environment beforehand.\n",
    "\n",
    "- Read ```MapPerformances.csv``` into the dataframe ```AllPerformances```.\n",
    "- Make a RainCloud-plot of the tasks (x-axis) and performance (y-axis) for both time conditions (3sec / Infinite). The y-axis should start at 0.25 and end at 0.75.\n",
    "- Have a look at ```help(pt.RainCloud)``` to get an overview of the different parameters that you can modify to create a nice raincloud-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-12b64f0d43ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Read MapPerformances.csv into the dataframe AllPerformances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mAllPerformances\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/MapPerformances.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#Make a RainCloud-plot of the tasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRainCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Performance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllPerformances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth_viol\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwidth_box\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#Read MapPerformances.csv into the dataframe AllPerformances\n",
    "AllPerformances =  pd.read_csv('./Data/MapPerformances.csv')\n",
    "\n",
    "#Make a RainCloud-plot of the tasks\n",
    "plot = pt.RainCloud(x='Task', y= 'Performance', hue='Time', data = AllPerformances,width_viol= 0.4,width_box=0.1).set_ylim(0.25,0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data of ```AllPerformances``` we now want to calculate a **two-way ANOVA**. A two-way ANOVA is a statistical test used to determine the effect of two nominal predictor variables (= independent variables) on a continuous outcome variable (= dependent variable).\n",
    "\n",
    "H$_{01}$ = The performance is the same for the different tasks. <br>\n",
    "H$_{02}$ = The performance is the same for the different time conditions. <br>\n",
    "H$_{03}$ = An interaction effect does not exist.\n",
    "\n",
    "- Given the null hypotheses above, what is the outcome variable and what are the predictor variables that you have to use for the two-way ANOVA?\n",
    "- Use ```statsmodels```’ ```ols``` function to create an ordinary least squares model as a precursor to the ANOVA. <br> The ```ols``` function takes the following: **ols(\"y ~ C(X1) * C(X2)\", df)**, where X1 and X2 are the predictor variables, y is the output variable and df is the dataframe of the used data.\n",
    "- With the result of the ols calculate a **type 2** two-way ANOVA using ```statsmodels```’ ```anova_lm```.\n",
    "- Based on the ANOVA table explain which of the null hypotheses can be rejected. What does this outcome tell you?\n",
    "\n",
    "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html), the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) and the [anova_lm documentation](http://www.statsmodels.org/dev/anova.html) to get a feeling how to use these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The factors 'tasks' and 'time conditions' are predictor variables \n",
      "  to the outcome variable 'performance'.\n",
      "  \n",
      "Hypothesis03, claiming that there is no difference in performancefor the different \n",
      "  time conditions can be rejected, because the ANOVA shows a significant result \n",
      "  (p<.05) for the factor Time\n"
     ]
    }
   ],
   "source": [
    "#outcome varaible and predictor variable\n",
    "print(\"The factors 'tasks' and 'time conditions' are predictor variables \\n  to the outcome variable 'performance'.\\n  \")\n",
    "\n",
    "#interpretion results\n",
    "print(\"Hypothesis03, claiming that there is no difference in performancefor the different \\n  time conditions can be rejected, because the ANOVA shows a significant result \\n  (p<.05) for the factor Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ordinary least squares model as a precursor\n",
    "precursor=ols('Performance~C(Time)*C(Task)', AllPerformances).fit()\n",
    "\n",
    "#With the result of the ols calculate a type 2 two-way ANOVA\n",
    "TwoWayAnova =anova_lm(precursor, typ=2)\n",
    "print(TwoWayAnova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Task Performance: 3sec Condition vs. Infinite Condition [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look onto the single time conditions by calculating a **one-way ANOVA** for each time condition (3sec and Infinite). A one-way ANOVA is a statistical test used to determine the effect of one nominal predictor variable (= independent variable) on a continuous outcome variable (= dependent variable). \n",
    "\n",
    "H$_{01}$ = The performance is the same for the different tasks. <br>\n",
    "\n",
    "- Use the data of ```AllPerformances``` and split it: Create ```SecPerformances``` with the data of the 3sec-condition and ```InfPerformances``` with the data of the Infinite-condition.\n",
    "- Given the null hypothesis above, what is the outcome variable and what is the predictor variable that you have to use for the one-way ANOVAs?\n",
    "\n",
    "Do for each dataset (SecPerformances, InfPerformances):\n",
    "\n",
    "- Use ```statsmodels```’ ```ols``` function to create an ordinary least squares model as a precursor to the ANOVA. The ```ols``` function takes the formula <br> The ```ols``` function takes the following: **ols(\"y ~ C(X)\", df)**, where X is the predictor variable, y is the output variable and df is the dataframe of the used data.\n",
    "- With the result of the ols calculate a **type 1** one-way ANOVA using ```statsmodels```’ ```anova_lm```.\n",
    "- Based on the ANOVA table explain if the null hypothesis can be rejected. What does this outcome tell you?\n",
    "\n",
    "Take a look at the [ols documentation](https://www.statsmodels.org/stable/index.html) and the [patsy documentation](https://patsy.readthedocs.io/en/v0.1.0/formulas.html) to get a feeling how to use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AllPerformances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-547b439166c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create SecPerformances with the data of the 3sec-condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSecPerformances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllPerformances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAllPerformances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'3sec'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Create InfPerformances with the data of the infinite-condition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mInfPerformances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAllPerformances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAllPerformances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'Infinite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AllPerformances' is not defined"
     ]
    }
   ],
   "source": [
    "# Create SecPerformances with the data of the 3sec-condition\n",
    "SecPerformances = AllPerformances[AllPerformances['Time']=='3sec']\n",
    "\n",
    "# Create InfPerformances with the data of the infinite-condition\n",
    "InfPerformances = AllPerformances[AllPerformances['Time']=='Infinite']\n",
    "\n",
    "#create ordinary least squares models(for both conditions/datasets) as a precursor to the ANOVA\n",
    "SecOls=ols('Performance~C(Task)', SecPerformances).fit()\n",
    "InfOls=ols('Performance~C(Task)', InfPerformances).fit()\n",
    "\n",
    "#With the result of the ols calculate a type 1 one-way ANOVA for both conditions/dataset\n",
    "SecAnova =anova_lm(SecOls, typ=1)\n",
    "InfAnova =anova_lm(InfOls, typ=1)\n",
    "print(SecAnova)\n",
    "print(InfAnova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the outcome of the ANOVA table one can see a non-signficant outcome \n",
      " for the SecPerformances Dataset, therefore the Null-hypothesis cannot be rejected. \n",
      "\n",
      "In opposite, the Dataset InfPerformances shows a significant result \n",
      " and the Hypothesis can be rejected for this dataset.\n"
     ]
    }
   ],
   "source": [
    "#interpretation\n",
    "print(\"Based on the outcome of the ANOVA table one can see a non-signficant outcome \\n for the SecPerformances Dataset, therefore the Null-hypothesis cannot be rejected. \\n\")\n",
    "\n",
    "print(\"In opposite, the Dataset InfPerformances shows a significant result \\n and the Hypothesis can be rejected for this dataset.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is a significant outcome for one of the datasets (SecPerformances or InfPerformances), make a post-hoc paired t-test using this dataset.\n",
    "\n",
    "- Extract the performances for each task (Absolute, Relative, Pointing).\n",
    "- Compare the performances of the different tasks pairwise using ```scipy.stats.ttest_rel```\n",
    "- Why do we need to do further post-hoc tests and what do they tell us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-27457e048b63>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-27457e048b63>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print(\"Absolute - Pointing: \"+str(stats.ttest_rel())\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#extracting performances for each task\n",
    "inf_abs, inf_rel, inf_point = [InfPerformances['Performance'][InfPerformances['Task']==task] for task in ['Absolute','Relative', 'Pointing']]\n",
    "\n",
    "#pairwise comparsongs of performances\n",
    "print(\"Absolute - Relative: \"+str(stats.ttest_rel())\n",
    "print(\"Absolute - Pointing: \"+str(stats.ttest_rel())\n",
    "print(\"Relative - Pointing: \"+str(stats.ttest_rel())\n",
    "\n",
    "#explanation post-hoc tests\n",
    "print(\"ANOVAS do only tell us whether there are signficant differences between any of the groups. So if the ANOVA returns a significant p-value it is necessary to perform further post-hoc tests to check between WHICH groups in fact exists the significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3: Testing Task Performance via Repeated Measures ANOVA [3 pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to take a closer look on the task performance (accuracy) also taking the different measurements into account to check if there are some **significant effects, i.e. p < 0.05**. For this purpose we have the averaged performances over 15 repeated measure subjects for three measurements. We will first of all visualize the averaged performances for each task for the three measurements with a catplot and then calculate a repeated measures ANOVA. \n",
    "\n",
    "- Read ```RepeatedPerformances.csv``` into the dataframe ```RepeatedPerformances```.\n",
    "- Make a catplot (kind='barplot') of the conditions (x-axis) and the performance (y-axis). The y-axis should start at 0 and end at 0.75.\n",
    "- Please note that the conditions in the dataframe correspond to the given \"conditions\" list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b6e0a8d07700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfor_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Condition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcatplot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Condition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Performance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfor_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mylim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xticklabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "#set up conditions\n",
    "conditions = [\"Absolute - 3sec \",\"Absolute - Infinite\",\"Relative - 3sec \",\"Relative - Infinite\",\"Pointing 3sec\",\"Pointing - Infinite\"]\n",
    "repdict = dict(zip([i for i in range(len(conditions))], conditions))\n",
    "\n",
    "# read data into datafram repeatedperformances\n",
    "RepeatedPerformances = pd.read_csv('./Data/RepeatedPerformances.csv')\n",
    "for_plot = RepeatedPerformances.copy()\n",
    "for_plot['Condition'].replace(repdict, inplace = True)\n",
    "  \n",
    "#barplot of conditions/performance\n",
    "catplot = sns.catplot(x='Condition', y='Performance', data=for_plot, kind='bar').set(ylim=(0, 0.75)).set_xticklabels(rotation=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a usable dataframe for the following analysis\n",
    "repgroup = RepeatedPerformances.groupby(['Measurement','Subject','Condition'], as_index=False)['Performance'].mean()\n",
    "\n",
    "#dataframe corresponds to given conditions\n",
    "RepeatedDf = pd.DataFrame(columns={'Measurement','Subject','Task','Time','Performance'})\n",
    "tasks = ['Absolute','Absolute','Relative','Relative','Pointing','Pointing']\n",
    "times = ['3sec','Infinite','3sec','Infinite','3sec','Infinite']\n",
    "for i in range(270):\n",
    "    RepeatedDf = RepeatedDf.append({'Subject':repgroup['Subject'][i]\n",
    "                                    ,'Measurement':repgroup['Measurement'][i]\n",
    "                                    ,'Task':tasks[repgroup['Condition'][i]]\n",
    "                                    ,'Time':times[repgroup['Condition'][i]]\n",
    "                                    ,'Performance':repgroup['Performance'][i]}\n",
    "                                   ,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the data of ```RepeatedDf``` we want to calculate a **(three-way) repeated measures ANOVA**. A (three-way) repeated measures ANOVA in general is a statistical test used to determine the effect of three nominal predictor variables (= within-subject factors) on a continuous outcome variable (= dependent variable). \n",
    "\n",
    "\n",
    "\n",
    "- What is the dependent variable and what are the within-subject factors that you have to use for the repeated measures ANOVA?\n",
    "- Formulate the null hypotheses that the repeated measures ANOVA has to test.\n",
    "- Calculate a repeated measures ANOVA using ```statsmodels```' ```AnovaRM```. \n",
    "- Based on the ANOVA table explain which of the null hypotheses can be rejected. What does this outcome tell you?\n",
    "\n",
    "Take a look at the [ANOVARM documentation](http://www.statsmodels.org/dev/generated/statsmodels.stats.anova.AnovaRM.html#statsmodels.stats.anova.AnovaRM) to get a feeling how to use this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The depedent variable is the factor 'performance', because we want to measure the effect \n",
      " of different tasks and different time conditions AFFECTING the performance. Within-subject \n",
      " factors therefore are the different conditions of task and time.\n"
     ]
    }
   ],
   "source": [
    "#dependent variable & within-subject-factors\n",
    "\n",
    "print(\"The depedent variable is the factor 'performance', because we want to measure the effect \\n of different points of measurement AFFECTING the performance. Within-subject \\n factors therefore are the different points of measurement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 = The performance does not change regarding time conditions within the three measurements.\n",
      "H2 = The performance does not change regarding the tasks within the three measurements.\n",
      "H3 = The performance does not change regarding time conditions and tasks (interaction-effect) within the three measurements.\n"
     ]
    }
   ],
   "source": [
    "#null-hypothesis\n",
    "print(\"H1 = The performance does not change regarding time conditions within the three measurements.\")\n",
    "print(\"H2 = The performance does not change regarding the tasks within the three measurements.\")\n",
    "print (\"H3 = The performance does not change regarding time conditions and tasks (interaction-effect) within the three measurements.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AnovaRM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-06b8b52a834c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#repeated measurement RM-ANOVA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Performance'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAnovaRM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRepeatedDf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdV\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'Subject'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwithin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregate_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AnovaRM' is not defined"
     ]
    }
   ],
   "source": [
    "#repeated measurement RM-ANOVA\n",
    "dV = 'Performance' \n",
    "results = AnovaRM(data=RepeatedDf, depvar=dV, subject= 'Subject', within=['Task', 'Time'], aggregate_func='mean')\n",
    "print(results.fit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The results show non-significant (p>.05) values for the main effect of TASK and the interaction effect of TASK*TIME. Hence, Null-Hypotheses 1 and 2 are true. In opposite, there is a signifant main effect for the factor TIME (p<.05) and Hypothesis1 can be rejected.\n"
     ]
    }
   ],
   "source": [
    "#results of RM-ANOVA\n",
    "print(\"The results show non-significant (p>.05) values for the main effect of TASK and the interaction effect of TASK*TIME. Hence, Null-Hypotheses 1 and 2 are true. In opposite, there is a signifant main effect for the factor TIME (p<.05) and Hypothesis1 can be rejected.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4: Spatial coverage of Seahaven [Bonus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better feeling of the spatial coverage of Seahaven, we can create an overview of the houses that the subjects have seen. With a colormap it is easy to display the spatial coverage in an intuitive way.\n",
    "\n",
    "- Open the image ```map5.png``` as ```SeahavenMap``` and read ```Clicks.csv``` into a dataframe ```NumClicks```.\n",
    "- Draw a solid circle for each house. Use the x- and y-coordinates of ```NumClicks``` for the positioning of the circles.\n",
    "- The column \"clicks\" from ```NumClicks``` displays how many subjects had visited the respective house. Use these click-values to calculate each circle's colour:\n",
    "\n",
    "$CircleColor = cmap((click[i]-min(clicks))/(max(clicks)-min(clicks)))$\n",
    "\n",
    "$clicks$: list/array of all click-values from the dataframe ```NumClicks``` <br>\n",
    "$click[i]$: a certain click-value from the dataframe ```NumClicks``` at position $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the files and extract the necessary data\n",
    "img = Image.open('./Data/map5.png')\n",
    "SeahavenMap = np.asarray(img, dtype = float)\n",
    "NumClicks = pd.read_csv('./Data/Clicks.csv')\n",
    "# set everything up to display the Seahaven Map\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "SeahavenMap.resize((450,500))\n",
    "ax = plt.subplot2grid((10, 10), (0, 0), colspan=9,rowspan=10)\n",
    "plt.imshow(SeahavenMap, aspect = 'equal')\n",
    "\n",
    "# choose a colormap for the circles that display the houses\n",
    "cmap = plt.cm.get_cmap('Reds')\n",
    "\n",
    "# draw the circles and give them the right color (using the given colormap)\n",
    "circle_pos= zip(NumClicks['x'].values.astype(int),NumClicks['y'].values.astype(int))\n",
    "clicks = NumClicks['clicks']\n",
    "circlecolors = []\n",
    "min_clicks = min(clicks)\n",
    "max_clicks = max(clicks)\n",
    "\n",
    "for i in range(len(clicks)):\n",
    "    circlecolors.append(cmap((click[i]-min_clicks)/((max_clicks-min_clicks))))\n",
    "for i,pos in enumerate(circle_pos):\n",
    "    circle = plt.Circle(pos,radius=3, color=circlecolors[i])\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "# set everything up to display the Colormap / legend for the circle's colors\n",
    "a=np.outer(np.arange(0,1,0.01),np.ones(3))\n",
    "ax2 = plt.subplot2grid((10, 10), (0, 9),rowspan=10)\n",
    "plt.imshow(a,aspect='auto',cmap='Reds',origin=\"lower\")\n",
    "ax2.get_xaxis().set_ticks([])\n",
    "ax2.get_yaxis().set_ticks(np.linspace(0,99,10))\n",
    "ax2.get_yaxis().set_ticklabels(np.linspace((min(clicks)/64)*100,(max(clicks)/64)*100,10,dtype=int))\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_ylabel(\"Percentage of Subjects That Have Seen This House\",rotation=270, fontsize=15, labelpad=20)\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
